{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ac1813-ad3b-4cc1-bf30-8633a3286afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ccb0e1-5cab-43be-b1c6-3aca6c0b96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                               text  \\\n",
      "0  3121               But the staff was so horrible to us.   \n",
      "1  2777  To be completely fair, the only redeeming fact...   \n",
      "2  2777  To be completely fair, the only redeeming fact...   \n",
      "3  1634  The food is uniformly exceptional, with a very...   \n",
      "4  2534  Where Gabriela personaly greets you and recomm...   \n",
      "\n",
      "            aspectCategory  polarity  \n",
      "0                  service  negative  \n",
      "1                     food  positive  \n",
      "2  anecdotes/miscellaneous  negative  \n",
      "3                     food  positive  \n",
      "4                  service  positive  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_path = '../Data/lab4_train.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17993d1-cd09-4a3c-8877-a55f6031b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['polarity'] != 'conflict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90e0d7d-4732-4c01-a0e2-a862a9a4d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100  # Define the maximum length of sequences\n",
    "\n",
    "# LSTM preprocessing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "X_lstm = tokenizer.texts_to_sequences(data['text'])\n",
    "X_lstm = pad_sequences(X_lstm, maxlen=max_len)\n",
    "\n",
    "# LDA preprocessing\n",
    "vectorizer = CountVectorizer()\n",
    "X_lda = vectorizer.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0faa82ff-9653-45c2-8b54-f9caeb37fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayad\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.6023 - loss: 0.9562 - val_accuracy: 0.6254 - val_loss: 0.8280\n",
      "Epoch 2/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6928 - loss: 0.6742 - val_accuracy: 0.6572 - val_loss: 0.7261\n",
      "Epoch 3/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8176 - loss: 0.4643 - val_accuracy: 0.6906 - val_loss: 0.7326\n",
      "Epoch 4/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8914 - loss: 0.2961 - val_accuracy: 0.6906 - val_loss: 0.8146\n",
      "Epoch 5/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9231 - loss: 0.1957 - val_accuracy: 0.6388 - val_loss: 0.8865\n",
      "Epoch 6/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.9312 - loss: 0.1900 - val_accuracy: 0.6756 - val_loss: 0.8887\n",
      "Epoch 7/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.9444 - loss: 0.1520 - val_accuracy: 0.6923 - val_loss: 0.9390\n",
      "Epoch 8/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9396 - loss: 0.1375 - val_accuracy: 0.6940 - val_loss: 1.0080\n",
      "Epoch 9/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9484 - loss: 0.1212 - val_accuracy: 0.6856 - val_loss: 1.1036\n",
      "Epoch 10/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9455 - loss: 0.1204 - val_accuracy: 0.6756 - val_loss: 1.0131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21bb7b86790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "max_len = 100\n",
    "\n",
    "# Encode the polarity column\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(data['polarity'])\n",
    "\n",
    "# Convert encoded labels to one-hot encoding\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: positive, negative, neutral\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_lstm, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee56674-d2d2-4a11-95ff-5ca41e5845e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression on LDA features: 0.7123745819397993\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert one-hot encoded y_train to 1D array\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Train logistic regression on LDA features\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train_labels)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Convert one-hot encoded y_test to multiclass format\n",
    "y_test_multiclass = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy score\n",
    "print(\"Accuracy of Logistic Regression on LDA features:\", accuracy_score(y_test_multiclass, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a1eeb3-0d84-42b6-9f22-516a24689fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step\n",
      "Accuracy of Stacked Model: 0.9595182335229173\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions from both models\n",
    "X_stacking = np.hstack((model.predict(X_lstm), lr.predict_proba(X_lda)))\n",
    "\n",
    "# Train a model on top of the combined predictions\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_stacking, y)\n",
    "\n",
    "# Evaluate the stacked model\n",
    "y_pred_stacking = clf.predict(X_stacking)\n",
    "print(\"Accuracy of Stacked Model:\", accuracy_score(y, y_pred_stacking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684c25c5-3e84-4f66-a91e-827d22c9eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of Stacked Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       715\n",
      "           1       0.98      0.92      0.95       398\n",
      "           2       0.97      0.98      0.97      1876\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2989\n",
      "   macro avg       0.96      0.94      0.95      2989\n",
      "weighted avg       0.96      0.96      0.96      2989\n",
      " samples avg       0.96      0.96      0.96      2989\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayad\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report for the stacked model\n",
    "print(\"Classification Report of Stacked Model:\")\n",
    "print(classification_report(y, y_pred_stacking))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
